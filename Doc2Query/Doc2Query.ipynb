{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Doc2Query.Doc2Query import Doc2Query\n",
    "from Doc2Query import Doc2Query\n",
    "import pyterrier as pt\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyterrier.datasets.IRDSDataset"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTerrier dataset to pass\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "type(pt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Doc2Query\n",
    "Doc2Query = Doc2Query(\"google/flan-t5-small\", temperatur=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents: 100%|██████████| 126958/126958 [00:02<00:00, 55643.10it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate queries for the dataset and extend the documents by the queries\n",
    "expanded_documents = Doc2Query.expandDocumentsByQueries('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': {0: \"A Study on Word Similarity using Context Vector Models\\n\\n\\n There is a need to measure word similarity when processing natural languages, especially when using generalization, classification, or example -based approaches. Usually, measures of similarity between two words are defined according to the distance between their semantic classes in a semantic taxonomy . The taxonomy approaches are more or less semantic -based that do not consider syntactic similarit ies. However, in real applications, both semantic and syntactic similarities are required and weighted differently. Word similarity based on context vectors is a mixture of syntactic and semantic similarit ies. In this paper, we propose using only syntactic related co-occurrences as context vectors and adopt information theoretic models to solve the problems of data sparseness and characteristic precision. The probabilistic distribution of co-occurrence context features is derived by parsing the contextual environment of each word , and all the context features are adjusted according to their IDF (inverse document frequency) values. The agglomerative clustering algorithm is applied to group similar words according to their similarity values. It turns out that words with similar syntactic categories and semantic classes are grouped together. ['Query 3: Word similarity using context vector models']\",\n",
       "  1: \"Bootstrapping Large Sense Tagged Corpora ['i was able to find the bootstrapping large Sense tagged corpora']\",\n",
       "  2: \"Headerless, Quoteless, but not Hopeless? Using Pairwise Email Classification to Disentangle Email Threads\\n\\n\\n Thread disentanglement is the task of separating out conversations whose thread structure is implicit, distorted, or lost. In this paper, we perform email thread disentanglement through pairwise classification, using text similarity measures on non-quoted texts in emails. We show that i) content text similarity metrics outperform style and structure text similarity metrics in both a class-balanced and class-imbalanced setting, and ii) although feature performance is dependent on the semantic similarity of the corpus, content features are still effective even when controlling for semantic similarity. We make available the Enron Threads Corpus, a newly-extracted corpus of 70,178 multiemail threads with emails from the Enron Email Corpus. ['Query 1: Headerless, Quoteless, but not Hopeless? Using Pair']\",\n",
       "  3: 'Aligning Words in {E}nglish-{H}indi Parallel Corpora\\n\\n\\n In this paper, we describe a word alignment algorithm for English-Hindi parallel data. The system was developed to participate in the shared task on word alignment for languages with scarce resources at the ACL 2005 workshop, on \"Building and using parallel texts: data driven machine translation and beyond\". Our word alignment algorithm is based on a hybrid method which performs local word grouping on Hindi sentences and uses other methods such as dictionary lookup, transliteration similarity, expected English words and nearest aligned neighbours. We trained our system on the training data provided to obtain a list of named entities and cognates and to collect rules for local word grouping in Hindi sentences. The system scored 77.03% precision and 60.68% recall on the shared task unseen test data. [\\'Query 1: Aligning words in English-H\\']',\n",
       "  4: \"Proposal of a very-large-corpus acquisition method by cell-formed registration ['a very-large-corpus acquisition method by cell-formed registration']\"}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_documents[['text']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index using PyTerrier\n",
    "indexer = pt.IterDictIndexer(\n",
    "    \"./indexes/index_Doc2Query-flan-t5-small\",\n",
    "    overwrite=True,\n",
    "    fields=[\"text\"],\n",
    "    meta=[\"docno\"]\n",
    ")\n",
    "# Index the documents\n",
    "indexref = indexer.index(expanded_documents)\n",
    "\n",
    "# Retrieve documents using BM25\n",
    "bm25 = pt.BatchRetrieve(indexref, wmodel=\"BM25\")\n",
    "\n",
    "# Perform retrieval\n",
    "#queries_df = pt_dataset.get_topics()\n",
    "#run = bm25.transform(queries_df)\n",
    "run = bm25(pt_dataset.get_topics('text'))\n",
    "\n",
    "# Evaluate the results\n",
    "qrels_df = pt_dataset.get_qrels()\n",
    "eval = pt.Evaluate(run, qrels_df, metrics=[\"map\", \"ndcg\", \"ndcg_cut.10\", \"recip_rank\", \"recall_100\"])\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter run to include only judged documents\n",
    "qrels_df = pt_dataset.get_qrels()\n",
    "judged_docnos = qrels_df['docno'].unique()\n",
    "filtered_run = run[run['docno'].isin(judged_docnos)]\n",
    "\n",
    "# Evaluate the results\n",
    "eval = pt.Evaluate(filtered_run, qrels_df, metrics=[\"map\", \"ndcg\", \"ndcg_cut.10\", \"recip_rank\", \"recall_100\"])\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the run file for subsequent evaluations\n",
    "#persist_and_normalize_run(run, system_name='Doc2Query-flan-t5-small-BM25-judged_only', default_output='../runs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
