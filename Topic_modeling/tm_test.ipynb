{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from topic_modeling import VAE, Encoder, Decoder, SparseDataset, topic_cos_sim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "cuda = False\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "#epochs = 10\n",
    "epochs = 10\n",
    "#batch_size = 8\n",
    "batch_size = 8\n",
    "#learning_rate = 1e-2\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # bow\\n# bow = {\\'O02-2002\\' : {\\'i\\': 2, \\'mixtur\\': 1, \\'adopt\\': 1, \\'exampl\\': 1, \\'featur\\': 2, \\'especi\\': 1, \\'classif\\': 1, \\'requir\\': 1, \\'gener\\': 1, \\'measur\\': 2, \\'idf\\': 1, \\'characterist\\': 1, \\'valu\\': 2, \\'languag\\': 1, \\'vector\\': 3, \\'environ\\': 1, \\'data\\': 1, \\'turn\\': 1}}\\n\\n\\nbow = {}\\nfor docid in range(doi.getNumberOfDocuments()):\\n  for posting in  di.getPostings(doi.getDocumentEntry(docid)):\\n    docno = meta.getItem(\"docno\", docid)\\n    if not docno in bow:\\n      bow[docno]= {}\\n    termid = posting.getId()\\n    lee = lex.getLexiconEntry(termid)\\n    bow[docno][lee.getKey()] = posting.getFrequency()\\n\\nprint(bow[\"O02-2002\"]) '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # bow\n",
    "# bow = {'O02-2002' : {'i': 2, 'mixtur': 1, 'adopt': 1, 'exampl': 1, 'featur': 2, 'especi': 1, 'classif': 1, 'requir': 1, 'gener': 1, 'measur': 2, 'idf': 1, 'characterist': 1, 'valu': 2, 'languag': 1, 'vector': 3, 'environ': 1, 'data': 1, 'turn': 1}}\n",
    "\n",
    "\n",
    "bow = {}\n",
    "for docid in range(doi.getNumberOfDocuments()):\n",
    "  for posting in  di.getPostings(doi.getDocumentEntry(docid)):\n",
    "    docno = meta.getItem(\"docno\", docid)\n",
    "    if not docno in bow:\n",
    "      bow[docno]= {}\n",
    "    termid = posting.getId()\n",
    "    lee = lex.getLexiconEntry(termid)\n",
    "    bow[docno][lee.getKey()] = posting.getFrequency()\n",
    "\n",
    "print(bow[\"O02-2002\"]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = index.getDirectIndex()\n",
    "doi = index.getDocumentIndex()\n",
    "lex = index.getLexicon()\n",
    "meta = index.getMetaIndex()\n",
    "\n",
    "test = True\n",
    "\n",
    "if test:\n",
    "  train_size = 64\n",
    "  val_size = 32\n",
    "else:\n",
    "  train_size = int(doi.getNumberOfDocuments() * 0.8)\n",
    "  val_size = doi.getNumberOfDocuments() - int(doi.getNumberOfDocuments() * 0.8)\n",
    "\n",
    "bow_sparse = sp.dok_matrix((train_size,len(lex)), dtype=np.int8)\n",
    "bow_sparse_val = sp.dok_matrix((val_size,len(lex)), dtype=np.int8)\n",
    "\n",
    "for docid in range(train_size + val_size):\n",
    "  docno = meta.getItem(\"docno\", docid)\n",
    "  # if docid == 0:\n",
    "    # print(docno)\n",
    "  for posting in  di.getPostings(doi.getDocumentEntry(docid)):\n",
    "    if posting.getFrequency() > 0:\n",
    "      termid = posting.getId()\n",
    "      lee = lex.getLexiconEntry(termid)\n",
    "      # if docid == 0:\n",
    "        # print(f\"{lee.getKey()} , {termid}\")\n",
    "      if docid < train_size:\n",
    "        bow_sparse[docid, termid] = posting.getFrequency()\n",
    "      else:\n",
    "        bow_sparse_val[docid - train_size, termid] = posting.getFrequency()\n",
    "      # if docid == 0:\n",
    "        # print(f\"{docid}\")\n",
    "        # print(f\"{bow_sparse[docid, termid]}\")\n",
    "\n",
    "bow_sparse = bow_sparse.tocsr()\n",
    "bow_sparse_val = bow_sparse_val.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 97223)\n",
      "7\n",
      "(32, 97223)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#print(bow_sparse[31])\n",
    "print(bow_sparse.shape)\n",
    "print(bow_sparse[31].todense().item(117))\n",
    "\n",
    "print(bow_sparse_val.shape)\n",
    "print(bow_sparse_val[31].todense().item(557))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dim = bow_sparse.shape\\ndevice = torch.device(device)\\nindptr = torch.tensor(bow_sparse.indptr, dtype=torch.int64, device=device)\\nindices = torch.tensor(bow_sparse.indices, dtype=torch.int64, device=device)\\ndata = torch.tensor(bow_sparse.data, dtype=torch.int8, device=device)\\n\\nprint(dim[0])\\n\\nidx = 0\\n\\nobs = torch.zeros((dim[1],), dtype=torch.int8, device=device)\\nprint(obs)\\nprint(len(obs))\\nprint(obs[0])\\nind1,ind2 = indptr[idx],indptr[idx+1]\\nobs[indices[ind1:ind2]] = data[ind1:ind2]\\nprint(obs.shape)\\nprint(obs)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dim = bow_sparse.shape\n",
    "device = torch.device(device)\n",
    "indptr = torch.tensor(bow_sparse.indptr, dtype=torch.int64, device=device)\n",
    "indices = torch.tensor(bow_sparse.indices, dtype=torch.int64, device=device)\n",
    "data = torch.tensor(bow_sparse.data, dtype=torch.int8, device=device)\n",
    "\n",
    "print(dim[0])\n",
    "\n",
    "idx = 0\n",
    "\n",
    "obs = torch.zeros((dim[1],), dtype=torch.int8, device=device)\n",
    "print(obs)\n",
    "print(len(obs))\n",
    "print(obs[0])\n",
    "ind1,ind2 = indptr[idx],indptr[idx+1]\n",
    "obs[indices[ind1:ind2]] = data[ind1:ind2]\n",
    "print(obs.shape)\n",
    "print(obs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SparseDataset(bow_sparse, device)\n",
    "val_dataset = SparseDataset(bow_sparse_val, device)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for batch, x in enumerate(train_loader):\\n    print(batch)\\n    for doc in x:\\n        for freq in doc:\\n            if freq > 0:\\n                print(freq)\\n                break;\\n    break '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" for batch, x in enumerate(train_loader):\n",
    "    print(batch)\n",
    "    for doc in x:\n",
    "        for freq in doc:\n",
    "            if freq > 0:\n",
    "                print(freq)\n",
    "                break;\n",
    "    break \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more hyperparameters\n",
    "\n",
    "input_dim  = len(lex)\n",
    "hidden_dim = 512\n",
    "latent_dim = 8\n",
    "\n",
    "# hidden_dim = 16384\n",
    "# latent_dim = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = input_dim)\n",
    "\n",
    "vae = VAE(encoder=encoder, decoder=decoder, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Encoder(\n",
      "    (lin1): Linear(in_features=97223, out_features=512, bias=True)\n",
      "    (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (mean): Linear(in_features=512, out_features=8, bias=True)\n",
      "    (var): Linear(in_features=512, out_features=8, bias=True)\n",
      "    (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lin1): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (out): Linear(in_features=512, out_features=97223, bias=True)\n",
      "    (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    logsoftmax = torch.log_softmax(x_hat,dim=1)\n",
    "    rec_loss = -1.0 * torch.sum(x*logsoftmax)\n",
    "\n",
    "    kl_div = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return rec_loss + kl_div\n",
    "\n",
    "optimizer = Adam(vae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE training:\n",
      "Epoch 1 :\tAverage Loss: 772.353271484375\n",
      "Epoch 2 :\tAverage Loss: 772.3255048479352\n",
      "Epoch 3 :\tAverage Loss: 771.7692260742188\n",
      "Epoch 4 :\tAverage Loss: 770.9572056361607\n",
      "Epoch 5 :\tAverage Loss: 770.9559151785714\n",
      "Epoch 6 :\tAverage Loss: 771.041255405971\n",
      "Epoch 7 :\tAverage Loss: 770.8846391950335\n",
      "Epoch 8 :\tAverage Loss: 771.0286298479352\n",
      "Epoch 9 :\tAverage Loss: 771.0865740094866\n",
      "Epoch 10 :\tAverage Loss: 770.8393467494419\n",
      "VAE training done\n"
     ]
    }
   ],
   "source": [
    "print(\"VAE training:\")\n",
    "vae.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch, x in enumerate(train_loader):\n",
    "\n",
    "        x = x.view(batch_size, input_dim)\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = vae(x)\n",
    "        \n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} :\\tAverage Loss: {overall_loss / (batch * batch_size)}\")\n",
    "    \n",
    "print(\"VAE training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97223\n",
      "tensor([3.0533e-18, 1.9681e-18, 3.1782e-17,  ..., 7.8412e-22, 1.8986e-21,\n",
      "        4.6304e-21])\n",
      "[0.25926107 0.06094712 0.1128213  0.06669614 0.14851014 0.03370682\n",
      " 0.19721784 0.12083951]\n",
      "97223\n",
      "tensor([3.1085e-18, 2.1252e-18, 4.7711e-17,  ..., 1.7223e-21, 2.9354e-21,\n",
      "        8.0158e-21])\n",
      "[0.19482163 0.04282981 0.04659067 0.09138741 0.12798983 0.33396128\n",
      " 0.03579765 0.12662166]\n",
      "97223\n",
      "tensor([7.0671e-20, 5.3585e-20, 1.2337e-18,  ..., 2.3188e-23, 5.0110e-23,\n",
      "        2.1341e-22])\n",
      "[0.10524561 0.20375174 0.02522157 0.16414607 0.25604492 0.04029632\n",
      " 0.09690887 0.10838488]\n",
      "97223\n",
      "tensor([2.0557e-22, 1.2258e-22, 4.6473e-21,  ..., 1.0828e-26, 3.7348e-26,\n",
      "        1.2705e-25])\n",
      "[0.05510388 0.7071533  0.01816019 0.00542881 0.05604247 0.04312894\n",
      " 0.09078204 0.0242003 ]\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, x in enumerate(val_loader):\n",
    "        x = x.view(batch_size, input_dim)\n",
    "        x = x.to(device)\n",
    "        \n",
    "        x_hat, mean, log_var = vae(x)\n",
    "        for doc in x_hat:\n",
    "            print(len(doc))\n",
    "            print(doc)\n",
    "            print(vae.inference_theta(doc))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "qid                                             1\n",
      "docid                                       94858\n",
      "docno                2004.cikm_conference-2004.47\n",
      "rank                                            0\n",
      "score                                   15.681777\n",
      "query    retrieval system improving effectiveness\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pyterrier' has no attribute 'EnglishSnowballStemmer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m qe \u001b[38;5;241m=\u001b[39m (pt\u001b[38;5;241m.\u001b[39mBatchRetrieve(index, wmodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m>>\u001b[39m \\\n\u001b[1;32m      2\u001b[0m       pt\u001b[38;5;241m.\u001b[39mapply\u001b[38;5;241m.\u001b[39mdoc_score(\u001b[38;5;28;01mlambda\u001b[39;00m doc : topic_cos_sim(doc, index, vae)))\n\u001b[0;32m----> 4\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mqe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m run\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/transformer.py:223\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    Sets up a default method for every transformer, which is aliased to transform() (for DataFrames)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    or transform_iter() (for iterable dictionaries) depending on the type of input. \u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_iter(\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/ops.py:335\u001b[0m, in \u001b[0;36mComposedPipeline.transform\u001b[0;34m(self, topics)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, topics):\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[0;32m--> 335\u001b[0m         topics \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m topics\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/apply_base.py:131\u001b[0m, in \u001b[0;36mApplyDocumentScoringTransformer.transform\u001b[0;34m(self, inputRes)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m add_ranks(outputRes)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_rowwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputRes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_df\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/apply_base.py:115\u001b[0m, in \u001b[0;36mApplyDocumentScoringTransformer._transform_rowwise\u001b[0;34m(self, outputRes)\u001b[0m\n\u001b[1;32m    113\u001b[0m     outputRes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m outputRes\u001b[38;5;241m.\u001b[39mprogress_apply(fn, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     outputRes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43moutputRes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m outputRes \u001b[38;5;241m=\u001b[39m add_ranks(outputRes)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputRes\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10033\u001b[0m )\n\u001b[0;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 963\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    982\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    983\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      1\u001b[0m qe \u001b[38;5;241m=\u001b[39m (pt\u001b[38;5;241m.\u001b[39mBatchRetrieve(index, wmodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m>>\u001b[39m \\\n\u001b[0;32m----> 2\u001b[0m       pt\u001b[38;5;241m.\u001b[39mapply\u001b[38;5;241m.\u001b[39mdoc_score(\u001b[38;5;28;01mlambda\u001b[39;00m doc : \u001b[43mtopic_cos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvae\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      4\u001b[0m run \u001b[38;5;241m=\u001b[39m qe(pt_dataset\u001b[38;5;241m.\u001b[39mget_topics(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      6\u001b[0m run\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/ir-lab-sose-2024-augsburg-information-retrieval/Topic_modeling/topic_modeling.py:109\u001b[0m, in \u001b[0;36mtopic_cos_sim\u001b[0;34m(doc, index, vae)\u001b[0m\n\u001b[1;32m    107\u001b[0m qid \u001b[38;5;241m=\u001b[39m doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    108\u001b[0m query \u001b[38;5;241m=\u001b[39m doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEnglishSnowballStemmer\u001b[49m\n\u001b[1;32m    111\u001b[0m freqs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyterrier' has no attribute 'EnglishSnowballStemmer'"
     ]
    }
   ],
   "source": [
    "\n",
    "qe = (pt.BatchRetrieve(index, wmodel=\"BM25\") % 10 >> \\\n",
    "      pt.apply.doc_score(lambda doc : topic_cos_sim(doc, index, vae)))\n",
    "\n",
    "run = qe(pt_dataset.get_topics('text'))\n",
    "\n",
    "run.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term743 Nt=14283 TF=28248 maxTF=2147483647 @{0 6743278 0} TFf=28248\n"
     ]
    }
   ],
   "source": [
    "lee = lex.getLexiconEntry(\"retriev\")\n",
    "print(lee)\n",
    "termid = lee.getTermId()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retriev'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
