{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from topic_modeling import VAE, Encoder, Decoder, SparseDataset, topic_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "cuda = False\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # bow\\n# bow = {\\'O02-2002\\' : {\\'i\\': 2, \\'mixtur\\': 1, \\'adopt\\': 1, \\'exampl\\': 1, \\'featur\\': 2, \\'especi\\': 1, \\'classif\\': 1, \\'requir\\': 1, \\'gener\\': 1, \\'measur\\': 2, \\'idf\\': 1, \\'characterist\\': 1, \\'valu\\': 2, \\'languag\\': 1, \\'vector\\': 3, \\'environ\\': 1, \\'data\\': 1, \\'turn\\': 1}}\\n\\n\\nbow = {}\\nfor docid in range(doi.getNumberOfDocuments()):\\n  for posting in  di.getPostings(doi.getDocumentEntry(docid)):\\n    docno = meta.getItem(\"docno\", docid)\\n    if not docno in bow:\\n      bow[docno]= {}\\n    termid = posting.getId()\\n    lee = lex.getLexiconEntry(termid)\\n    bow[docno][lee.getKey()] = posting.getFrequency()\\n\\nprint(bow[\"O02-2002\"]) '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # bow\n",
    "# bow = {'O02-2002' : {'i': 2, 'mixtur': 1, 'adopt': 1, 'exampl': 1, 'featur': 2, 'especi': 1, 'classif': 1, 'requir': 1, 'gener': 1, 'measur': 2, 'idf': 1, 'characterist': 1, 'valu': 2, 'languag': 1, 'vector': 3, 'environ': 1, 'data': 1, 'turn': 1}}\n",
    "\n",
    "\n",
    "bow = {}\n",
    "for docid in range(doi.getNumberOfDocuments()):\n",
    "  for posting in  di.getPostings(doi.getDocumentEntry(docid)):\n",
    "    docno = meta.getItem(\"docno\", docid)\n",
    "    if not docno in bow:\n",
    "      bow[docno]= {}\n",
    "    termid = posting.getId()\n",
    "    lee = lex.getLexiconEntry(termid)\n",
    "    bow[docno][lee.getKey()] = posting.getFrequency()\n",
    "\n",
    "print(bow[\"O02-2002\"]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = index.getDirectIndex()\n",
    "doi = index.getDocumentIndex()\n",
    "lex = index.getLexicon()\n",
    "meta = index.getMetaIndex()\n",
    "\n",
    "test = True\n",
    "\n",
    "if test:\n",
    "  train_size = 64\n",
    "  val_size = 32\n",
    "else:\n",
    "  train_size = int(doi.getNumberOfDocuments() * 0.8)\n",
    "  val_size = doi.getNumberOfDocuments() - int(doi.getNumberOfDocuments() * 0.8)\n",
    "\n",
    "bow_sparse = sp.dok_matrix((train_size,len(lex)), dtype=np.int8)\n",
    "bow_sparse_val = sp.dok_matrix((val_size,len(lex)), dtype=np.int8)\n",
    "\n",
    "for docid in range(train_size + val_size):\n",
    "  docno = meta.getItem(\"docno\", docid)\n",
    "  # if docid == 0:\n",
    "    # print(docno)\n",
    "  for posting in  di.getPostings(doi.getDocumentEntry(docid)):\n",
    "    if posting.getFrequency() > 0:\n",
    "      termid = posting.getId()\n",
    "      lee = lex.getLexiconEntry(termid)\n",
    "      # if docid == 0:\n",
    "        # print(f\"{lee.getKey()} , {termid}\")\n",
    "      if docid < train_size:\n",
    "        bow_sparse[docid, termid] = posting.getFrequency()\n",
    "      else:\n",
    "        bow_sparse_val[docid - train_size, termid] = posting.getFrequency()\n",
    "      # if docid == 0:\n",
    "        # print(f\"{docid}\")\n",
    "        # print(f\"{bow_sparse[docid, termid]}\")\n",
    "\n",
    "bow_sparse = bow_sparse.tocsr()\n",
    "bow_sparse_val = bow_sparse_val.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 97223)\n",
      "7\n",
      "(32, 97223)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#print(bow_sparse[31])\n",
    "print(bow_sparse.shape)\n",
    "print(bow_sparse[31].todense().item(117))\n",
    "\n",
    "print(bow_sparse_val.shape)\n",
    "print(bow_sparse_val[31].todense().item(557))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dim = bow_sparse.shape\\ndevice = torch.device(device)\\nindptr = torch.tensor(bow_sparse.indptr, dtype=torch.int64, device=device)\\nindices = torch.tensor(bow_sparse.indices, dtype=torch.int64, device=device)\\ndata = torch.tensor(bow_sparse.data, dtype=torch.int8, device=device)\\n\\nprint(dim[0])\\n\\nidx = 0\\n\\nobs = torch.zeros((dim[1],), dtype=torch.int8, device=device)\\nprint(obs)\\nprint(len(obs))\\nprint(obs[0])\\nind1,ind2 = indptr[idx],indptr[idx+1]\\nobs[indices[ind1:ind2]] = data[ind1:ind2]\\nprint(obs.shape)\\nprint(obs)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dim = bow_sparse.shape\n",
    "device = torch.device(device)\n",
    "indptr = torch.tensor(bow_sparse.indptr, dtype=torch.int64, device=device)\n",
    "indices = torch.tensor(bow_sparse.indices, dtype=torch.int64, device=device)\n",
    "data = torch.tensor(bow_sparse.data, dtype=torch.int8, device=device)\n",
    "\n",
    "print(dim[0])\n",
    "\n",
    "idx = 0\n",
    "\n",
    "obs = torch.zeros((dim[1],), dtype=torch.int8, device=device)\n",
    "print(obs)\n",
    "print(len(obs))\n",
    "print(obs[0])\n",
    "ind1,ind2 = indptr[idx],indptr[idx+1]\n",
    "obs[indices[ind1:ind2]] = data[ind1:ind2]\n",
    "print(obs.shape)\n",
    "print(obs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SparseDataset(bow_sparse, device)\n",
    "val_dataset = SparseDataset(bow_sparse_val, device)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for batch, x in enumerate(train_loader):\\n    print(batch)\\n    for doc in x:\\n        for freq in doc:\\n            if freq > 0:\\n                print(freq)\\n                break;\\n    break '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" for batch, x in enumerate(train_loader):\n",
    "    print(batch)\n",
    "    for doc in x:\n",
    "        for freq in doc:\n",
    "            if freq > 0:\n",
    "                print(freq)\n",
    "                break;\n",
    "    break \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more hyperparameters\n",
    "\n",
    "input_dim  = len(lex)\n",
    "hidden_dim = 512\n",
    "latent_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = input_dim)\n",
    "\n",
    "vae = VAE(encoder=encoder, decoder=decoder, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Encoder(\n",
      "    (lin1): Linear(in_features=97223, out_features=512, bias=True)\n",
      "    (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (mean): Linear(in_features=512, out_features=8, bias=True)\n",
      "    (var): Linear(in_features=512, out_features=8, bias=True)\n",
      "    (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lin1): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (out): Linear(in_features=512, out_features=97223, bias=True)\n",
      "    (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    logsoftmax = torch.log_softmax(x_hat,dim=1)\n",
    "    rec_loss = -1.0 * torch.sum(x*logsoftmax)\n",
    "\n",
    "    kl_div = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return rec_loss + kl_div\n",
    "\n",
    "optimizer = Adam(vae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE training:\n",
      "Epoch 1 :\tAverage Loss: 772.3536202566964\n"
     ]
    }
   ],
   "source": [
    "print(\"VAE training:\")\n",
    "vae.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch, x in enumerate(train_loader):\n",
    "\n",
    "        x = x.view(batch_size, input_dim)\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = vae(x)\n",
    "        \n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1} :\\tAverage Loss: {overall_loss / (batch * batch_size)}\")\n",
    "    \n",
    "print(\"VAE training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97223\n",
      "tensor([1.0582e-11, 5.9681e-12, 4.2424e-11,  ..., 5.2480e-14, 2.8021e-14,\n",
      "        5.2323e-14])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VAE' object has no attribute 'vae'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(doc))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_theta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/ir-lab-sose-2024-augsburg-information-retrieval/Topic_modeling/topic_modeling.py:28\u001b[0m, in \u001b[0;36mVAE.inference_theta\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minference_theta\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 28\u001b[0m         mean, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae\u001b[49m\u001b[38;5;241m.\u001b[39mencode(x)\n\u001b[1;32m     29\u001b[0m         z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterization(mean, torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m log_var))\n\u001b[1;32m     30\u001b[0m         theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(z,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VAE' object has no attribute 'vae'"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, x in enumerate(val_loader):\n",
    "        x = x.view(batch_size, input_dim)\n",
    "        x = x.to(device)\n",
    "        \n",
    "        x_hat, mean, log_var = vae(x)\n",
    "        for doc in x_hat:\n",
    "            print(len(doc))\n",
    "            print(doc)\n",
    "            print(vae.inference_theta(doc))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "VAE(\n",
      "  (encoder): Encoder(\n",
      "    (lin1): Linear(in_features=97223, out_features=512, bias=True)\n",
      "    (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (mean): Linear(in_features=512, out_features=8, bias=True)\n",
      "    (var): Linear(in_features=512, out_features=8, bias=True)\n",
      "    (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lin1): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (out): Linear(in_features=512, out_features=97223, bias=True)\n",
      "    (LeakyReLU): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      ")\n",
      "5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pyterrier/batchretrieve.py\", line 39, in score\n",
      "    return self.fn(keyFreq, posting, entryStats, collStats)\n",
      "  File \"/tmp/ipykernel_212414/3836122188.py\", line 1, in <lambda>\n",
      "    topic_reranker = lambda keyFreq, posting, entryStats, collStats : topic_cos_sim(keyFreq, posting, entryStats, collStats, vae)\n",
      "  File \"/workspaces/ir-lab-sose-2024-augsburg-information-retrieval/Topic_modeling/topic_modeling.py\", line 102, in topic_cos_sim\n",
      "    q_theta = vae.inference_theta(query_bow)\n",
      "  File \"/workspaces/ir-lab-sose-2024-augsburg-information-retrieval/Topic_modeling/topic_modeling.py\", line 28, in inference_theta\n",
      "    mean, log_var = self.vae.encode(x)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1729, in __getattr__\n",
      "    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
      "AttributeError: 'VAE' object has no attribute 'vae'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 146, in jnius.py_invoke0\n",
      "  File \"jnius/jnius_conversion.pxi\", line 583, in jnius.convert_python_to_jobject\n",
      "TypeError: must be real number, not NoneType\n"
     ]
    },
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: java.lang.NullPointerException",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJavaException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_reranker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m keyFreq, posting, entryStats, collStats : topic_cos_sim(keyFreq, posting, entryStats, collStats, vae)\n\u001b[1;32m      3\u001b[0m qe \u001b[38;5;241m=\u001b[39m (pt\u001b[38;5;241m.\u001b[39mBatchRetrieve(index, wmodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m>>\u001b[39m pt\u001b[38;5;241m.\u001b[39mBatchRetrieve(index, wmodel\u001b[38;5;241m=\u001b[39mtopic_reranker))\n\u001b[0;32m----> 5\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mqe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m run\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/transformer.py:223\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    Sets up a default method for every transformer, which is aliased to transform() (for DataFrames)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    or transform_iter() (for iterable dictionaries) depending on the type of input. \u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_iter(\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/ops.py:335\u001b[0m, in \u001b[0;36mComposedPipeline.transform\u001b[0;34m(self, topics)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, topics):\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[0;32m--> 335\u001b[0m         topics \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m topics\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/batchretrieve.py:441\u001b[0m, in \u001b[0;36mBatchRetrieve.transform\u001b[0;34m(self, queries)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28miter\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m), total\u001b[38;5;241m=\u001b[39mqueries\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m:\n\u001b[0;32m--> 441\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno_provided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocno_provided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocid_provided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocid_provided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores_provided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscores_provided\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(res)\n\u001b[1;32m    444\u001b[0m res_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocid\u001b[39m\u001b[38;5;124m'\u001b[39m ] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/batchretrieve.py:352\u001b[0m, in \u001b[0;36mBatchRetrieve._retrieve_one\u001b[0;34m(self, row, input_results, docno_provided, docid_provided, scores_provided)\u001b[0m\n\u001b[1;32m    349\u001b[0m     srq\u001b[38;5;241m.\u001b[39msetControl(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.terrier.matching.ScoringMatching\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m srq\u001b[38;5;241m.\u001b[39mgetControl(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# now ask Terrier to run the request\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunSearchRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m result \u001b[38;5;241m=\u001b[39m srq\u001b[38;5;241m.\u001b[39mgetResults()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# check we got all of the expected metadata (if the resultset has a size at all)\u001b[39;00m\n",
      "File \u001b[0;32mjnius/jnius_export_class.pxi:877\u001b[0m, in \u001b[0;36mjnius.JavaMethod.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mjnius/jnius_export_class.pxi:971\u001b[0m, in \u001b[0;36mjnius.JavaMethod.call_method\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mjnius/jnius_utils.pxi:79\u001b[0m, in \u001b[0;36mjnius.check_exception\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mJavaException\u001b[0m: JVM exception occurred: java.lang.NullPointerException"
     ]
    }
   ],
   "source": [
    "\n",
    "topic_reranker = lambda keyFreq, posting, entryStats, collStats : topic_cos_sim(keyFreq, posting, entryStats, collStats, vae)\n",
    "\n",
    "qe = (pt.BatchRetrieve(index, wmodel=\"BM25\") % 10 >> pt.BatchRetrieve(index, wmodel=topic_reranker))\n",
    "\n",
    "run = qe(pt_dataset.get_topics('text'))\n",
    "\n",
    "run.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
