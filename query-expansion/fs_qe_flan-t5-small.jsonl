[
    {
        "query_id": "1",
        "query": "retrieval system improving effectiveness",
        "llm_expansion": "Positional relevance model for pseudo-relevance feedback. Pseudo-relevance feedback is an effective technique for improving retrieval results."
    },
    {
        "query_id": "2",
        "query": "machine learning language identification",
        "llm_expansion": "Mangalore-University@INLI-FIRE-2017: Indian Native Language Identification using Support Vector Machines and Ensemble approach This paper describes the systems submitted by our team for Indian Native Language Identification (INLI) task held in conjunction with FIRE 2017."
    },
    {
        "query_id": "3",
        "query": "social media detect self harm",
        "llm_expansion": "Social media detects self harm"
    },
    {
        "query_id": "4",
        "query": "stemming for arabic languages",
        "llm_expansion": "This paper summarizes the contributions of the PRHLT-UPV team as a participant in the eRisk 2020 tasks on self-harm detection and prediction of depression levels from social media."
    },
    {
        "query_id": "5",
        "query": "audio based animal recognition",
        "llm_expansion": "In this paper we describe the architecture of an interactive thematic map search engine, Frankenplace, designed to facilitate document exploration at the intersection of theme and place. The map interface enables a user to zoom the geographic context of their query in and out, and quickly explore through thousands of search results in a meaningful way. And by combining topic models with geographically contextualized search results, users can discover related topics based on geographic context. Frankenplace utilizes a novel indexing method called geoboost for boosting terms associated with cells on a discrete global grid. The resulting index factors in the geographic scale of the place or feature mentioned in related text, the relative textual scope of the place reference, and the overall importance of the containing document in the document network. The system is currently indexed with over 5 million documents from the web, including the English Wikipedia and online travel blog entries. We demonstrate that Frankenplace utilizes "
    },
    {
        "query_id": "6",
        "query": "comparison different retrieval models",
        "llm_expansion": "A novel lemmatization algorithm for the Arabic Language."
    },
    {
        "query_id": "7",
        "query": "cache architecture",
        "llm_expansion": "In recent years the inverted lists evaluation model along with holistic stack-based algorithms have been established as the most prominent techniques for evaluating XML queries on large persistent XML data. In this framework, we are using materialized views for optimizing query performance, we define and address the following problem (view configuration problem): given an XML tree and its schema find a template of tree-pattern views (view configuration) such that: (a) the views of this configuration can answer all the queries that can be issued against the schema, (b) their materialization fits in the space provided, and (c) evaluating the queries using these views minimizes the overall query evaluation cost. We consider an instance of this problem for tree pattern queries. Our intension is to find view configurations whose materializations are small enough to be stored in main memory. We find two candidate solution configurations and we identify cases where views can be excluded from material"
    },
    {
        "query_id": "8",
        "query": "document scoping formula",
        "llm_expansion": "This paper discusses the concept of hyper questions to devise effective aggregation methods."
    },
    {
        "query_id": "9",
        "query": "pseudo relevance feedback",
        "llm_expansion": "The following is a list of the following:"
    },
    {
        "query_id": "10",
        "query": "how to represent natural conversations in word nets",
        "llm_expansion": "In this paper, we present a comprehensive study on the research of the user fatigue in online recommender systems. By analyzing user behavioral logs from Bing Now news recommendation, we find that user fatigue is a severe problem that greatly affects the user experience. We also notice that different users engage differently with repeated recommendations. Depending on the previous users' interaction with repeated recommendations, we illustrate that under certain condition the previously seen items should be demoted, while some other times they should be promoted."
    },
    {
        "query_id": "11",
        "query": "algorithm acceleration with nvidia cuda",
        "llm_expansion": "The recent advances in neural network-based machine learning algorithms promise a revolution in prediction-based tasks in a variety of domains. Of these, forecasting user activity in social media is particularly relevant for problems such as modeling and predicting information diffusion and designing intervention techniques to mitigate disinformation campaigns. Social media seems an ideal context for applying neural network techniques, as they provide large datasets and challenging prediction objectives."
    },
    {
        "query_id": "12",
        "query": "mention of algorithm",
        "llm_expansion": "The general model and simulation algorithms for bibliographic retrieval systems presented in an earlier paper I are expanded.The general model and simulation algorithms for bibliographic retrieval systems presented in an earlier paper I are expanded.The general model and simulation algorithms for bibliographic retrieval systems presented in an earlier paper I are expanded."
    },
    {
        "query_id": "13",
        "query": "at least three authors",
        "llm_expansion": "The eRisk 2019 Lab at the CLEF workshop is a research project on the development of transfer and supervised learning techniques for predicting the severity and risk of depression."
    },
    {
        "query_id": "14",
        "query": "german domain",
        "llm_expansion": "This paper focuses on ad hoc retrieval and ad hoc retrieval."
    },
    {
        "query_id": "15",
        "query": "mention of open source",
        "llm_expansion": "This paper summarizes the contributions of the PRHLT-UPV team as a participant in the eRisk 2020 tasks on self-harm detection and prediction of depression levels from social media."
    },
    {
        "query_id": "16",
        "query": "inclusion of text mining",
        "llm_expansion": "Probabilistic Topic Models for Text Data Retrieval and Analysis. Text data include all kinds of natural language text such as web pages, news articles, scienti c literature, emails, enterprise documents, and social media posts. As text data continues to grow quickly, it is increasingly important to develop intelligent systems to help people manage and make use of vast amounts of text data (\"big text data \") for various tasks, especially those involving complex decision-making. Logically, to harness big text data, we would need to rst identify the relevant text data to a particular application problem (i.e., perform Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by"
    },
    {
        "query_id": "17",
        "query": "the ethics of artificial intelligence",
        "llm_expansion": "This paper presents deep learning techniques for audio-based bird identification in soundscapes. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify 659 species. Deep Convolutional Neural Networks are trained to classify"
    },
    {
        "query_id": "19",
        "query": "machine learning for more relevant results",
        "llm_expansion": "We propose CUDA-DClust, a massively parallel algorithm for density-based clustering for the use of a Graphics Processing Unit (GPU)"
    },
    {
        "query_id": "20",
        "query": "crawling websites using machine learning",
        "llm_expansion": "This paper describes a novel graph-based ranking oriented recommendation algorithm that exploits both explicit and implicit feedback of users."
    },
    {
        "query_id": "21",
        "query": "recommenders influence on users",
        "llm_expansion": "The massive spread of digital information to which our society is subjected nowadays has led to a great amount of false or extremely biased information being shared and consumed by Internet users every day."
    },
    {
        "query_id": "22",
        "query": "search engine caching effects",
        "llm_expansion": "This article introduces an architecture for a document-partitioned search engine, based on a novel approach combining collection selection and load balancing, called load-driven routing. By exploiting the query-vector document model, and the incremental caching technique, our architecture can compute very high quality results for any query, with only a fraction of the computational load used in a typical document-partitioned architecture. By trading off a small fraction of the results, our technique allows us to strongly reduce the computing pressure to a search engine back-end; we are able to retrieve more than 2/3 of the top-5 results for a given query with only 10% the computing load needed by a configuration where the query is processed by each index partition. Alternatively, we can slightly increase the load up to 25% to improve precision and get more than 80% of the top-5 results. In fact, the flexibility of our system allows"
    },
    {
        "query_id": "23",
        "query": "consumer product reviews",
        "llm_expansion": "We present a cluster-based resampling method to select novel pseudo-relevant documents based on Lavrenko's relevance model approach. The main idea is to use overlapping clusters to find dominant documents for the initial retrieval set, and to repeatedly use these documents to emphasize the core topics of a query. The hypothesis behind using overlapping clusters is that a good representative document for a query may have several nearest neighbors with high similarities, participating in several different clusters. Experimental results on large-scale web TREC collections show significant improvements over the baseline relevance model on all collections, resulting in better retrieval accuracy, ultimately approaching true relevance feedback."
    },
    {
        "query_id": "24",
        "query": "limitations machine learning",
        "llm_expansion": "Query-level loss functions for information retrieval"
    },
    {
        "query_id": "25",
        "query": "medicine related research",
        "llm_expansion": "We propose an unsupervised learning technique for extracting information about authors and topics from large text corpora. We model documents as if they were generated by a two-stage stochastic process."
    },
    {
        "query_id": "26",
        "query": "natural language processing",
        "llm_expansion": "We propose an end-to-end speller correction system, namely CloudSpeller. The CloudSpeller system uses a Hidden Markov Model to effectively model major types of spelling errors in a unified framework, in which we integrate a large-scale lexicon constructed using Wikipedia, an error model trained from high confidence correction pairs, and the Microsoft Web N-gram service."
    },
    {
        "query_id": "27",
        "query": "graph based ranking",
        "llm_expansion": "In this paper, we propose a new design, called, IIoT-SIDefender (IIoT-SID), we measure security degree of Sensitive Information via Analytic Hierarchy Process (AHP) and Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS), based on selected taint tracking and real-time memory modification, attack-defense and fix-distribution approaches are proposed. To our best knowledge, no effective method can detect secret trace of SI thieves in Advanced Persistent Threat (APT), especially for backdoors and vulnerabilities in software or firmware. To deal with these problems, we propose a new design, called, IIoT-SIDefender (IIoT-SID), we measure security degree of Sensitive Information via Analytic Hierarchy Process (AHP) and Technique for Order Preference by Similarity"
    },
    {
        "query_id": "28",
        "query": "medical studies that use information retrieval",
        "llm_expansion": "The purpose of this paper is to provide a novel approach to identifying abbreviation and acronyms from clinical notes and map them to the UMLS (Unified Medical Language System) CUI (Concept Unique Identifier)."
    },
    {
        "query_id": "29",
        "query": "information retrieval on different language sources",
        "llm_expansion": "We propose a list-wise deep neural network based architecture to model the limited user behaviors within each session. To train the model efficiently, we first design a session embedding method to pre-train a session representation, which incorporates different kinds of user search behaviors such as clicks and views. Based on the learnt session representation, we further propose a list-wise ranking model to generate the recommendation result for each anonymous user session."
    },
    {
        "query_id": "30",
        "query": "papers that compare multiple information retrieval methods",
        "llm_expansion": "This paper proposes a simple alternative mechanism for preventing script injection attacks with browser-enforced embedded policies. Web sites that accept and display content such as wiki articles or comments typically filter the content to prevent injected script code from running in browsers that view the site. The diversity of browser rendering algorithms and the desire to allow rich content make filtering quite difficult, however, and attacks such as the Samy and Yamanner worms have exploited filtering weaknesses."
    },
    {
        "query_id": "31",
        "query": "risks of information retrieval in social media",
        "llm_expansion": "The use of social media has profoundly affected social and political dynamics in the Arab world. In this paper, we explore the Arabic microblogs retrieval. We illustrate some of the challenges associated with Arabic microblog retrieval, which mainly stem from the use of different Arabic dialects that vary in lexical selection, morphology, and phonetics and lack orthographic and spelling conventions."
    },
    {
        "query_id": "32",
        "query": "actual experiments that strengthen theoretical knowledge",
        "llm_expansion": "We propose to develop a framework for an intelligent reasoner with capabilities that support complex decision making processes in medical diagnosis. Identifying the causes, reasoning the effects to explore information geometry and learning the associated factors, from medical forum information extracted, are the core aspects of this work. As part of the proposed framework, we present an approach that identifies semantically similar causes and effects for any specific disease from medical diagnosis literature using implicit semantic interconnections among the medical terms. First we crawled MedHelp 1 forum data and considered two types of information: forums data and posts data. Each forum link points to a specific disease and consists of several topics pertaining to that disease. Each topic consists of multiple posts that carry either users' queries/difficulties or doctor's feedback pertaining to the issue(s) of the users. We performed a systematic evaluation to identify the relevance of the contextual information retrieved for a specific disease and similar factors"
    },
    {
        "query_id": "33",
        "query": "fake news detection",
        "llm_expansion": "This paper focuses on a novel approach for detecting false news."
    },
    {
        "query_id": "34",
        "query": "multimedia retrieval",
        "llm_expansion": "The University of Hildesheim submitted to the CLEF eRisk 2020 shared task on detecting early signs of self-harm in social media posts."
    },
    {
        "query_id": "35",
        "query": "processing natural language for information retrieval",
        "llm_expansion": "The purpose of this tutorial is to systematically explain this emerging axiomatic approach to developing optimal retrieval models, review and summarize the research progress achieved so far on this topic, and discuss promising future research directions in optimizing general retrieval models."
    },
    {
        "query_id": "36",
        "query": "recommendation systems",
        "llm_expansion": "We investigate the instinctive connection between query rewriting and semantic matching tasks, and propose a co-training framework to address the data sparseness problem when training deep neural networks."
    },
    {
        "query_id": "37",
        "query": "personalised search in e commerce",
        "llm_expansion": "This paper explores the use of online multi-task learning for search query spelling correction, by effectively transferring information from different and biased training datasets for improving search query spelling correction across datasets."
    },
    {
        "query_id": "38",
        "query": "sentiment analysis",
        "llm_expansion": "We present a general framework for such an active feedback problem, and derive several practical algorithms as special cases. Empirical evaluation of these algorithms shows that the performance of traditional relevance feedback (presenting the top K documents) is consistently worse than that of presenting documents with more diversity. With a diversity-based selection algorithm, we obtain fewer relevant documents, however, these fewer documents have more learning benefits."
    },
    {
        "query_id": "39",
        "query": "informational retrieval using neural networks",
        "llm_expansion": "A new probabilistic model based on the Dirichlet compound multinomial distribution"
    },
    {
        "query_id": "40",
        "query": "query log analysis",
        "llm_expansion": "In this tutorial, we focus on the last two goals, providing a fairly comprehensive overview of the scalability and e ciency challenges in large-scale web search engines. In this tutorial, we focus on the last two goals, providing an in-depth architectural overview of ad-hoc search tasks. In this tutorial, we focus on the last two goals, providing an in-depth architectural overview of ad-hoc search tasks. In this tutorial, we focus on the last two goals, providing an in-depth architectural overview of ad-hoc search tasks. In this tutorial, we focus on the last two goals, providing an in-depth architectural overview of ad-hoc ranking: passage retrieval and document retrieval. In our thesis we plan to address these shortcomings. First, we plan to make contextualization efficient enough to to be usable in resource constrained environments, and second we plan to use the efficient contextualization components"
    },
    {
        "query_id": "41",
        "query": "entity recognition",
        "llm_expansion": "In this paper, we show the first set of inverted indexes which work naturally for strings as well as phrase searching. The central idea is to exclude document d in the inverted list of a string P if every occurrence of P in d is subsumed by another string of which P is a prefix. With this we show that our space utilization is close to the optimal. Techniques from succinct data structures are deployed to achieve compression while allowing fast access in terms of frequency and document id based retrieval. For phrase searching, we show that our indexes compare favorably against a typical inverted index deploying position-wise intersections. For phrase searching, we show that our indexes compare favorably against a typical inverted index deploying position-wise intersections. For phrase searching, we show that our indexes compare favorably against a typical inverted index deploying"
    },
    {
        "query_id": "42",
        "query": "relevance assessments",
        "llm_expansion": "A Deep Bayesian Tensor-Based System for Video Recommendation With the availability of abundant online multi-relational video information, recommender systems that can effectively exploit these sorts of data and suggest creatively interesting items will become increasingly important."
    },
    {
        "query_id": "43",
        "query": "deep neural networks",
        "llm_expansion": "The purpose of this tutorial is to systematically explain this emerging axiomatic approach to developing optimal retrieval models, review and summarize the research progress achieved so far on this topic, and discuss promising future research directions in optimizing general retrieval models."
    },
    {
        "query_id": "44",
        "query": "information retrieval",
        "llm_expansion": "This paper shows that Q-measure inherits both the reliability of noninterpolated Average Precision and the multigrade relevance capability of Average Weighted Precision through a theoretical analysis, and then verify the above claim through experiments by actually ranking the systems submitted to the NTCIR-3 CLIR Task."
    },
    {
        "query_id": "45",
        "query": "analysis for android apps",
        "llm_expansion": "The purpose of this paper is to present the results of a multi-stage learning model for early detection of signs of anorexia and self-harm on social media."
    },
    {
        "query_id": "46",
        "query": "the university of amsterdam",
        "llm_expansion": "The challenge for the next decade is to explore the multiple dimensions and components of the new generation of information retrieval systems by experimenting with a diversity of evaluative approaches."
    },
    {
        "query_id": "47",
        "query": "neural ranking for ecommerce product search",
        "llm_expansion": "We propose link-based techniques for automatic detection of Web spam, a term referring to pages which use deceptive techniques to obtain undeservedly high scores in search engines. The use of Web spam is widespread and difficult to solve, mostly due to the large size of the Web which means that, in practice, many algorithms are infeasible.We perform a statistical analysis of a large collection of Web pages. In particular, we compute statistics of the links in the vicinity of every Web page applying rank propagation and probabilistic counting over the entire Web graph in a scalable way. These statistical features are used to build Web spam classifiers which only consider the link structure of the Web, regardless of page contents. We then present a study of the performance of each of the classifiers alone, as well as their combined performance, by testing them over a large collection of Web link spam. After tenfold cross-validation,"
    },
    {
        "query_id": "48",
        "query": "web pages evolution",
        "llm_expansion": "We show that by performing a simple reordering of the target symbols in the compressed text (more precisely, reorganizing the bytes into a wavelet-treelike shape) and using little additional space, searching capabilities are greatly improved without a drastic impact in compression and decompression times."
    },
    {
        "query_id": "49",
        "query": "exhaustivity of index",
        "llm_expansion": "The simplest way to extract the situational information from the Twitter social media during disasters is to extract the situational information from the social media."
    },
    {
        "query_id": "50",
        "query": "query optimization",
        "llm_expansion": "We present a method for detecting Web spam."
    },
    {
        "query_id": "51",
        "query": "cosine similarity vector",
        "llm_expansion": "The recent advances in neural network-based machine learning algorithms promise a revolution in prediction-based tasks in a variety of domains. Of these, forecasting user activity in social media is particularly relevant for problems such as modeling and predicting information diffusion and designing intervention techniques to mitigate disinformation campaigns. Social media seems an ideal context for applying neural network techniques, as they provide large datasets and challenging prediction objectives."
    },
    {
        "query_id": "52",
        "query": "reverse indexing",
        "llm_expansion": "The reverse indexing method is used to index the information systems."
    },
    {
        "query_id": "53",
        "query": "index compression techniques",
        "llm_expansion": "In the past, the simplest index compression techniques were used to compress the index."
    },
    {
        "query_id": "54",
        "query": "search engine optimization with query logs",
        "llm_expansion": "This paper describes the participation of the Bioinformatics group of the Institute of Electronics and Engineering Informatics of University of Aveiro in the shared tasks of CLEF eRisk 2019 1. The major question raised in information retrieval on semi-structured document like XML. For these purposes, we present a model for the semi-structured information retrieval, based on the possibilistic networks. The documentelements and elements -terms relations are modelled by measures of possibility and necessity. In this model, the user's query starts a process of propagation to recover documents or portions of documents necessarily or at least possibly relevant. An example of such a research is proposed in order to illustrate the presented approach."
    },
    {
        "query_id": "55",
        "query": "bm25",
        "llm_expansion": "We propose a general query-optimization framework that treats regular and restructured views in a uniform manner and is applicable to SQL select-project-join queries and views with or without aggregation."
    },
    {
        "query_id": "56",
        "query": "what makes natural language processing natural",
        "llm_expansion": "In this paper we present an analysis of an AltaVista Search Engine query log consisting of approximately 1 billion entries for search requests over a period of six weeks. This represents almost 285 million user sessions, each an attempt to fill a single information need."
    },
    {
        "query_id": "57",
        "query": "principle of a information retrieval indexing",
        "llm_expansion": "In many QA systems, fine-grained named entities are extracted by coarse-grained named entity recognizer and fine-grained named entity dictionary. In many QA systems, fine-grained named entity recognition and AIU archived about 26% improvement over QA with passage retrieval. The result demonstrated that our approach is effective for QA."
    },
    {
        "query_id": "58",
        "query": "architecture of web search engine",
        "llm_expansion": "The most comprehensive analysis of a web search engine voice query log is the architecture of a web search engine."
    },
    {
        "query_id": "59",
        "query": "what is ahp",
        "llm_expansion": "The first strategy is to formalize heuristics as constraints, and use constraint analysis to analytically check the implementation of retrieval heuristics. The second strategy is to define a set of relevance-preserving perturbations and perform diagnostic tests to empirically evaluate how well a retrieval function implements retrieval heuristics."
    },
    {
        "query_id": "60",
        "query": "what is information retrieval",
        "llm_expansion": "Learning query and document similarities from click-through bipartite graph with metadata. We consider learning query and document similarities from a click-through bipartite graph with metadata on the nodes. The metadata contains multiple types of features of queries and documents. We propose solving the problems in a principled way. Specifically, we use two different linear mappings to project the queries and documents in two different feature spaces into the same latent space, and take the dot product in the latent space as their similarity. Query-query and document-document similarities can also be naturally defined as dot products in the latent space. We further solve the learning problem by using a new technique called Multi-view Partial Least Squares (M-PLS). The advantages include the global optimum which can be obtained through Singular Value Decomposition (SVD) and the capability of finding high quality similar queries. We conducted large scale"
    },
    {
        "query_id": "61",
        "query": "efficient retrieval algorithms",
        "llm_expansion": "The best way to retrieve a greater number of documents related to the users' query is to use a stemming algorithm to retrieve a greater number of documents related to the users' query."
    },
    {
        "query_id": "62",
        "query": "how to avoid spam results",
        "llm_expansion": "This paper presents deep learning techniques for audio-based bird identification at very large scale. Deep Convolutional Neural Networks (DCNNs) are fine-tuned to classify 1500 species. Various data augmentation techniques are applied to prevent overfitting and to further improve model accuracy and generalization. The proposed approach is evaluated in the BirdCLEF 2018 campaign and provides the best system in all subtasks. It surpasses previous state-of-the-art by 15.8 % identifying foreground species and 20.2 % considering also background species achieving a mean reciprocal rank (MRR) of 82.7 % and 74.0 % on the official BirdCLEF Subtask1 test set."
    },
    {
        "query_id": "63",
        "query": "information retrieval with algorithms",
        "llm_expansion": "In this paper, we propose a method for predicting the ranking position of a Web page. Assuming a set of successive past top-k rankings, we study the evolution of Web pages in terms of ranking trend sequences used for Markov Models training, which are in turn used to predict future rankings. The predictions are highly accurate for all experimental setups and similarity measures."
    },
    {
        "query_id": "64",
        "query": "misspellings in queries",
        "llm_expansion": "We investigate potential strategies to mine queries and searcher histories for clues that could help search engines choose the most appropriate information to present in response to exploratory medical queries."
    },
    {
        "query_id": "65",
        "query": "information in different language",
        "llm_expansion": "The present work proposes a novel framework for extracting and summarizing situational information from microblog streams posted during disaster scenarios."
    },
    {
        "query_id": "66",
        "query": "abbreviations in queries",
        "llm_expansion": "Locality Preserving Indexing is a novel algorithm for document indexing."
    },
    {
        "query_id": "67",
        "query": "lemmatization algorithms",
        "llm_expansion": "The first step in determining graph pattern queries is to develop a novel type system for RDF graph pattern queries."
    },
    {
        "query_id": "68",
        "query": "filter ad rich documents",
        "llm_expansion": "This paper presents deep learning techniques for audio-based bird identification in soundscapes."
    },
    {
        "query_id": "18",
        "query": "advancements in information retrieval",
        "llm_expansion": "The Linguistic String Project (LSP) natural language processing system has been developed as a domain-independent natural language processing system. Initially utilized for processing sets of medical messages and other texts in the medical domain, it has been used at the Naval Research Laboratory for processing Navy messages about shipboard equipment failures. From our experience in transporting the Linguistic String Project (LSP) natural language processing system, we identify the features that are required for transportable natural language systems."
    }
]