{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGzfwnRt8zLN"
      },
      "source": [
        "# Finetuning the model\n",
        "\n",
        "In this Notebook I try finetuning the embedding model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCGgaqKK8zLO"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqSiUi7r8zLP"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers faiss-gpu faiss-cpu torch\n",
        "#!pip install tira ir-datasets python-terrier\n",
        "#!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1gOGlJp8zLP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pyterrier as pt\n",
        "import faiss\n",
        "\n",
        "# Encoder and Tokenizer models\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Tira and Pyterrier Imports\n",
        "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
        "from tira.third_party_integrations import ir_datasets\n",
        "from tira.rest_api_client import Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIWS2vBG8zLP",
        "outputId": "7a3d3e4c-23e5-478d-cbd3-1b8cfa7cd08b"
      },
      "outputs": [],
      "source": [
        "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
        "ensure_pyterrier_is_loaded()\n",
        "tira = Client()\n",
        "\n",
        "# Print options for pandas\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", None)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option('display.float_format', '{:.5f}'.format)\n",
        "\n",
        "\n",
        "# Use GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdHEt0wc8zLQ"
      },
      "source": [
        "## Dataset and Text Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_j3rZcj8zLQ",
        "outputId": "e15f0594-8260-4dc4-fffe-62dc28668d7c"
      },
      "outputs": [],
      "source": [
        "from modules.data import load_corpus, train_test_split, relevant_corpus\n",
        "\n",
        "corpus_path = \"./dataset_corpus.json\"\n",
        "corpus = load_corpus(corpus_path) # TODO: corpus preprocessing?\n",
        "\n",
        "# For testing on smaller corpus\n",
        "dataset = pt.get_dataset(\"irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training\")\n",
        "corpus = relevant_corpus(corpus, dataset)\n",
        "\n",
        "train_texts, val_texts = train_test_split(corpus)\n",
        "print(f\"{len(train_texts)} training samples, {len(val_texts)} val samples.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgJu2jqz8zLQ"
      },
      "source": [
        "## MLM Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFX_BZDH8zLQ",
        "outputId": "43bcbaf2-9b92-4e87-971e-1064754e7157"
      },
      "outputs": [],
      "source": [
        "from modules.model import FTModel\n",
        "from modules.dataset import get_dataloader\n",
        "from modules.train import train\n",
        "\n",
        "\n",
        "# the model\n",
        "model_name = \"prajjwal1/bert-tiny\"\n",
        "mode = \"mlm\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = FTModel(model_name, mode)\n",
        "\n",
        "train_dataloader = get_dataloader(tokenizer, train_texts, mode, batch_size=4, shuffle=True)\n",
        "val_dataloader = get_dataloader(tokenizer, val_texts, mode, batch_size=4, shuffle=False)\n",
        "\n",
        "print(\"Starting Training\")\n",
        "trained_model = train(model, train_dataloader, val_dataloader, epochs=3, lr=2e-5, mode=mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmLJ7xnJOps8",
        "outputId": "51160c1b-6f06-471d-e983-300c4621e52a"
      },
      "outputs": [],
      "source": [
        "new_name = \"bert-tiny-ft-mlm-ep3\"\n",
        "\n",
        "encoder = trained_model.model.model\n",
        "encoder.save_pretrained(new_name)\n",
        "tokenizer.save_pretrained(new_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHHb6YOm8zLQ"
      },
      "source": [
        "## Contrastive Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCBNZRvm8zLR"
      },
      "outputs": [],
      "source": [
        "from modules.model import FtModel\n",
        "from modules.dataset import get_dataloader\n",
        "from modules.train import train\n",
        "\n",
        "# the model\n",
        "model_name = \"prajjwal1/bert-tiny\"\n",
        "mode = \"contrastive\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = FTModel(model_name, mode)\n",
        "\n",
        "train_dataloader = get_dataloader(tokenizer, train_texts, mode, batch_size=4, shuffle=True)\n",
        "val_dataloader = get_dataloader(tokenizer, val_texts, mode, batch_size=4, shuffle=True)\n",
        "\n",
        "print(\"Starting Training\")\n",
        "trained_model = train(model, train_dataloader, val_dataloader, epochs=1, lr=2e-5, mode=mode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjvzp8I6VAKa"
      },
      "source": [
        "## (Colab) save model into drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR6t3pplVBf3",
        "outputId": "d295954c-b78d-44ac-ee50-7f5ae47f7912"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G-MsqyIyVg-a",
        "outputId": "5b093669-8f30-488d-d670-3311dccf253c"
      },
      "outputs": [],
      "source": [
        "from shutil import copyfile, copytree\n",
        "\n",
        "quelle = f\"/content/{new_name}\"\n",
        "ziel = \"/content/drive/My Drive/models/\" + quelle.split(\"/\")[-1]\n",
        "copytree(quelle, ziel)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
